Automeris io genome assembly and annotation

############# Hifi assembly
#!/bin/bash 
#SBATCH --job-name=Automeris_io__assembly_hifiasm 
#SBATCH -o %A_%a.8822_Automeris_record_assembly.out 
#SBATCH --mail-user=chelseaskoj@ufl.edu
#SBATCH --mail-type=FAIL,END 
#SBATCH -c 30 
#SBATCH --mem-per-cpu=5gb 
#SBATCH -t 30:00:00 
#SBATCH --account=kawahara 
#SBATCH --qos=kawahara
date;hostname;pwd 
module load ufrc 
module load hifiasm
hifiasm -o /blue/kawahara/chelseaskoj/Genome_Automeris/Genome_Automeris_1stassembly.asm -l 3 -t 30 /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_pacbio/NS2800/outputs/m64219e_220702_224701.hifi_reads.fastq.gz


######## Assembly Python

#! /usr/bin/env python
import numpy as np
from itertools import groupby
import json
import sys

def fasta_iter(fasta_file):
    """Takes a FASTA file, and produces a generator of Header and Sequences.
    This is a memory-efficient way of analyzing a FASTA files -- without
    reading the entire file into memory.

    Parameters
    ----------
    fasta_file : str
        The file location of the FASTA file

    Returns
    -------
    header: str
        The string contained in the header portion of the sequence record
        (everything after the '>')
    seq: str
        The sequence portion of the sequence record
    """

    fh = open(fasta_file)
    fa_iter = (x[1] for x in groupby(fh, lambda line: line[0] == ">"))
    for header in fa_iter:
        # drop the ">"
        header = next(header)[1:].strip()
        # join all sequence lines to one.
        seq = "".join(s.upper().strip() for s in next(fa_iter))
        yield header, seq

def read_genome(fasta_file):
    """Takes a FASTA file, and produces 2 lists of sequence lengths. It also
    calculates the GC Content, since this is the only statistic that is not
    calculated based on sequence lengths.

    Parameters
    ----------
    fasta_file : str
        The file location of the FASTA file

    Returns
    -------
    contig_lens: list
        A list of lengths of all contigs in the genome.
    scaffold_lens: list
        A list of lengths of all scaffolds in the genome.
    gc_cont: float
        The percentage of total basepairs in the genome that are either G or C.
    """

    gc = 0
    total_len = 0
    contig_lens = []
    scaffold_lens = []
    for _, seq in fasta_iter(fasta_file):
        scaffold_lens.append(len(seq))
        if "NN" in seq:
            contig_list = seq.split("NN")
        else:
            contig_list = [seq]
        for contig in contig_list:
            if len(contig):
                gc += contig.count('G') + contig.count('C')
                total_len += len(contig)
                contig_lens.append(len(contig))
    gc_cont = (gc / total_len) * 100
    return contig_lens, scaffold_lens, gc_cont

def calculate_stats(seq_lens, gc_cont):
    stats = {}
    seq_array = np.array(seq_lens)
    stats['sequence_count'] = seq_array.size
    stats['gc_content'] = gc_cont
    sorted_lens = seq_array[np.argsort(-seq_array)]
    stats['longest'] = int(sorted_lens[0])
    stats['shortest'] = int(sorted_lens[-1])
    stats['median'] = np.median(sorted_lens)
    stats['mean'] = np.mean(sorted_lens)
    stats['total_bps'] = int(np.sum(sorted_lens))
    csum = np.cumsum(sorted_lens)
    for level in [10, 20, 30, 40, 50]:
        nx = int(stats['total_bps'] * (level / 100))
        csumn = min(csum[csum >= nx])
        l_level = int(np.where(csum == csumn)[0])
        n_level = int(sorted_lens[l_level])

        stats['L' + str(level)] = l_level
        stats['N' + str(level)] = n_level
    return stats

if __name__ == "__main__":
    infilename = sys.argv[1]
    contig_lens, scaffold_lens, gc_cont = read_genome(infilename)
    contig_stats = calculate_stats(contig_lens, gc_cont)
    scaffold_stats = calculate_stats(scaffold_lens, gc_cont)
    stat_output = {'Contig Stats': contig_stats,
                   'Scaffold Stats': scaffold_stats}
    print(json.dumps(stat_output, indent=2, sort_keys=True))

###Kmer

#!/bin/bash 
#SBATCH --job-name=Automeris_kmer23 
#SBATCH -o Automeris_kmer23_%j.out 
#SBATCH --mail-type=FAIL,END 
#SBATCH --mail-user=chelseaskoj@ufl.edu
#SBATCH -c 3 
#SBATCH --mem-per-cpu=4gb 
#SBATCH -t 00:30:00 
#SBATCH --account=kawahara 
#SBATCH --qos=kawahara

module load kmc/3.2.1
# create directory for kmc temporary files
mkdir kmc_tmp

kmc -k23 /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_pacbio/NS2800/outputs/m64219e_220702_224701.hifi_reads.fastq.gz 23xmers kmc_tmp

# Having the k-mers counted it is possible to dump KMC binary database to textual form with kmc_tools.
kmc_tools transform 21mers dump 23mers.txt 
kmc_tools transform 21mers histogram 23mer_reads.histo


#### BUSCO





########  Haplotig Purge

#!/bin/bash
#SBATCH --job-name=HapPur_s1_Aut
#SBATCH -o Aut_happurge_s1.out
#SBATCH --mail-type=FAIL,END
#SBATCH --mail-user=chelseaskoj@ufl.edu
#SBATCH --mem-per-cpu=4gb
#SBATCH -t 13:00:00
#SBATCH -c 4

module load minimap/2.21
module load samtools/1.15
module load purge_haplotigs/1.1.2
module load libssl/1.0.2l

purge_haplotigs hist  \
-b /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_purge1017.aln.bam \
-g /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_assembly_purge.fasta



########## Haplotig Purge 2

#!/bin/bash
#SBATCH --job-name=Autom_purge_s2
#SBATCH -o Autom_s2_purge_cut.log
#SBATCH --mail-type=FAIL,END
#SBATCH --mail-user=chelseaksoj@ufl.edu
#SBATCH --mem-per-cpu=2gb
#SBATCH -t 1:00:00
#SBATCH -c 4
#SBATCH --account=kawahara
#SBATCH --qos=kawahara-b

module load samtools/1.15
module load purge_haplotigs/1.1.2
module load libssl/1.0.2l

purge_haplotigs cov \
-i /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris.aln.sorted.bam.gencov    \
-l 5  \
-m 18  \
-h 75  \
-o coverage_stats.csv \
-j 80 \
-s 80

#!/bin/bash

#SBATCH --job-name=Autom_s3_purge_
#SBATCH -o Autom_purge1024_haplotigs.log
#SBATCH --mail-type=FAIL,END
#SBATCH --mail-user=chelseaskoj@ufl.edu
#SBATCH --mem-per-cpu=8gb
#SBATCH -t 3:00:00
#SBATCH -c 4
#SBATCH --account=kawahara
#SBATCH --qos=kawahara

module load minimap/2.21
module load bedtools/2.30.0
module load samtools/1.15
module load purge_haplotigs/1.1.2
module load libssl/1.0.2l

purge_haplotigs purge  \
-g /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_assembly_purge.fasta \
-c /blue/kawahara/chelseaskoj/Genome_Automeris/coverage_stats1024.csv \
-o Automeris_assembly_purge2_1024


#### BUSCO

#!/bin/bash
#SBATCH --job-name=Automeris_busco_purge_masked
#SBATCH -o Automeris_masked_new_1128Busco.out 
#SBATCH --mail-type=FAIL,END
#SBATCH --mail-user=chelseaskoj@ufl.edu 
#SBATCH --mem-per-cpu=2gb 
#SBATCH -t 3:00:00 
#SBATCH -c 6
#SBATCH --account=kawahara
export BUSCO_CONFIG_FILE=/blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_busco/config.ini 
export AUGUSTUS_CONFIG_PATH=/blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_busco/ 
echo $BUSCO_CONFIG_FILE 
module load busco/5.2.0 
busco -f -i /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_assembly_purge.fasta.masked  \
 -o BUSCO_Automeris_masked_1128 -l /data/reference/busco/v5/lineages/lepidoptera_odb10 \
 -m genome -c 6


 
######### Blobtools
#!/bin/sh
#SBATCH --job-name=Automeris_blob
#SBATCH --output=Automeris_blob_%j.out
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=chelseaskoj@ufl.edu
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=20gb
#SBATCH --time 04:00:00
#SBATCH --qos=kawahara
#SBATCH --account=kawahara

pwd; hostname; date

## Run blob tools
 
module load blobtools/1.0

blobtools create -i Genome_Automeris_1stassembly.asm.bp.p_ctg.fa -b Automeris.aln.sorted.bam -t Automeris_megablast.nt --nodes nodes.dmp --names names.dmp -o Automeris_blob_result

## You can then view and plot
blobtools view -i Automeris_blob_result.blobDB.json
blobtools plot -i Automeris_blob_result.blobDB.json




######### Minimap2
#!/bin/sh
#SBATCH --job-name=Automeris_minimap2
#SBATCH --output=Automeris_purge1017_minimap2_%j.out
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=chelseaskoj@ufl.edu
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=32gb
#SBATCH --time=08:00:00
#SBATCH --account=kawahara
#SBATCH --qos=kawahara

pwd; hostname; date

module load minimap2

minimap2 -ax map-pb /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_assembly_purge.fasta /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_pacbio/NS2800/outputs/m64219e_220702_224701.hifi_reads.fastq.gz > Automeris_purge1017.sam

module load samtools
#convert SAM file to BAM file
samtools view -S -b Automeris_purge1017.sam > Automeris_purge1017.bam

#Use samtools sort to convert the BAM file to a coordinate sorted BAM file
samtools sort Automeris_purge1017.bam > Automeris_purge1017.aln.bam

#index a genome sorted bAM file for quick alignment
samtools index Automeris_purge1017.aln.bam > Automeris_indexed_1017_sorted_bam


###### Mega blast
#!/bin/sh
#SBATCH --job-name=Automeris_megablast
#SBATCH --output=Automeris_megablast_%j.out
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=chelseaskoj@ufl.edu
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=10
#SBATCH --mem=30gb
#SBATCH --time 8-00:00:00
#SBATCH --qos=kawahara
#SBATCH --account=kawahara

pwd; hostname; date

module load ncbi_blast
blastn -db nt -task megablast -query /blue/kawahara/chelseaskoj/Genome_Automeris/Genome_Automeris_1stassembly.asm.bp.p_ctg.fa -out Automeris_megablast.nt -evalue 1e-5 -outfmt "6 qseqid staxids bitscore sgi staxids sskingdoms sscinames" -max_target_seqs 1 -num_threads=10


##### Annotation #####

#### Repeat Modeler

#!/bin/bash
#SBATCH --job-name=Automeris_repeatmod
#SBATCH -o %A_%a.Automeris_repeatmod.out
#SBATCH --mail-type=FAIL,END
#SBATCH --mail-user=chelseaskoj@ufl.edu
#SBATCH -c 20
#SBATCH --mem-per-cpu=8gb
#SBATCH -t 5-00:00:00
#SBATCH --account=kawahara
#SBATCH --qos=kawahara

date;hostname;pwd

module load repeatmodeler/2.0
module load seqkit/2.0.0

BuildDatabase -name Automeris_io /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_assembly_purge.fasta

RepeatModeler -database Automeris_io -pa 32 -LTRStruct >& run.adp.out

# you can break the known and unknown repeats into separate fasta files

cat Automeris_io-families.fa | seqkit fx2tab | awk '{ print "Automeris_1.0_"$0 }' | seqkit tab2fx > Automeris_io-families.prefix.fa
cat Automeris_io-families.prefix.fa | seqkit fx2tab | grep -v "Unknown" | seqkit tab2fx > Automeris_io.prefix.fa.known
cat Automeris_io-families.prefix.fa | seqkit fx2tab | grep "Unknown" | seqkit tab2fx > Automeris_io.prefix.fa.unknown



#### Repeat Masker

#!/bin/bash
#SBATCH --job-name=rmask_Automeris_io_1121
#SBATCH -o %A_%a.1121rm_Automeris.out
#SBATCH --mail-user=chelseaskoj@ufl.edu
#SBATCH --mail-type=FAIL,END
#SBATCH -c 8
#SBATCH --mem-per-cpu=8gb
#SBATCH -t 90:00:00
#SBATCH --account=kawahara
#SBATCH --qos=kawahara

date;hostname;pwd

module load repeatmasker/4.1.1

RepeatMasker -pa 8 -a -s -xsmall -gff -no_is -lib Automeris_io-families.fa /blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_assembly_purge.fasta
 &> RMask.Opt1_Automeris.adp.out


##### ProtHint 

#!/bin/bash
#SBATCH --job-name=%x_%jProhint_Autom
#SBATCH --output=%xc_%j.logAutomeris
#SBATCH --mail-user=rkeating.godfrey@ufl.edu
#SBATCH --mail-type=FAIL,END
#SBATCH --mem-per-cpu=4gb
#SBATCH --time=24:00:00
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --qos=kawahara-b

dates;hostname;pwd

genome=${1}
protein=${2}

module load prothint/2.6.0

module load genemark_es/4.69


prothint.py --threads ${SLURM_CPUS_ON_NODE:-1} ${genome} ${protein}


######### Braker2
#!/bin/bash
#SBATCH --job-name=%j_Automeris_braker2_prot
#SBATCH --output=%j_Automeris_braker2_prot.log
#SBATCH --mail-user=Chelseaskoj@ufl.edu
#SBATCH --mail-type=FAIL,END
#SBATCH --mem-per-cpu=8gb
#SBATCH --time=48:00:00
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=32
#SBATCH --account=kawahara
#SBATCH --qos=kawahara-b 
dates;hostname;pwd

genome=${1}
protein_gff=${2}
species=${3}

module load conda
module load braker/2.1.6

braker.pl \
--AUGUSTUS_CONFIG_PATH=/blue/kawahara/chelseaskoj/Genome_Automeris/Automeris_busco/Augustus/config \
--genome=${genome} --species ${species} --hints=${protein_gff} --softmasking --gff3 --cores 32 --AUGUSTUS_ab_initio




